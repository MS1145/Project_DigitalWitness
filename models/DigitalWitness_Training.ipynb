{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Digital Witness - LSTM Model Training\n",
        "\n",
        "This notebook trains the LSTM behavior classifier for the Digital Witness system.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "## Step 1: Mount Google Drive & Extract Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if zip file exists\n",
        "import os\n",
        "zip_path = \"/content/drive/MyDrive/DigitalWitness.zip\"\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    print(\"Found DigitalWitness.zip in Google Drive!\")\n",
        "else:\n",
        "    print(\"ERROR: DigitalWitness.zip not found in Google Drive root!\")\n",
        "    print(\"Please upload the zip file to your Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_project"
      },
      "outputs": [],
      "source": [
        "# Extract project files\n",
        "!unzip -q \"/content/drive/MyDrive/DigitalWitness.zip\" -d /content/\n",
        "\n",
        "# List extracted contents\n",
        "!ls /content/Project_DigitalWitness/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## Step 2: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision ultralytics opencv-python-headless mediapipe numpy\n",
        "print(\"Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## Step 3: Verify GPU & Check Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"GPU STATUS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected! Training will be slow.\")\n",
        "    print(\"Go to Runtime → Change runtime type → T4 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_data"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Check training data\n",
        "project_root = Path(\"/content/Project_DigitalWitness\")\n",
        "normal_dir = project_root / \"data\" / \"training\" / \"normal\"\n",
        "shoplifting_dir = project_root / \"data\" / \"training\" / \"shoplifting\"\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"TRAINING DATA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "normal_videos = list(normal_dir.glob(\"*.mp4\")) if normal_dir.exists() else []\n",
        "shoplifting_videos = list(shoplifting_dir.glob(\"*.mp4\")) if shoplifting_dir.exists() else []\n",
        "\n",
        "print(f\"Normal videos: {len(normal_videos)}\")\n",
        "print(f\"Shoplifting videos: {len(shoplifting_videos)}\")\n",
        "\n",
        "if len(normal_videos) == 0 or len(shoplifting_videos) == 0:\n",
        "    print(\"\\nERROR: Training videos not found!\")\n",
        "    print(f\"Expected in: {normal_dir}\")\n",
        "    print(f\"Expected in: {shoplifting_dir}\")\n",
        "else:\n",
        "    print(\"\\nTraining data ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## Step 4: Train the LSTM Model\n",
        "\n",
        "This will:\n",
        "1. Initialize CNN (ResNet18) for feature extraction\n",
        "2. Process all training videos\n",
        "3. Train LSTM classifier\n",
        "4. Save model to `models/lstm_classifier.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_model"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/Project_DigitalWitness')\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs('/content/Project_DigitalWitness/models', exist_ok=True)\n",
        "\n",
        "from src.models.train_deep_model import train_lstm_classifier\n",
        "\n",
        "# Train the model\n",
        "# Adjust parameters as needed:\n",
        "# - epochs: more epochs = better accuracy but longer training\n",
        "# - max_videos_per_class: set to 10-20 for quick test, None for full training\n",
        "\n",
        "results = train_lstm_classifier(\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.001,\n",
        "    val_split=0.2,\n",
        "    max_videos_per_class=None  # Set to 10 for quick test\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"TRAINING RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "if results.get('success'):\n",
        "    print(f\"Model saved: {results['model_path']}\")\n",
        "    print(f\"Training accuracy: {results['info']['final_train_acc']:.1%}\")\n",
        "    print(f\"Validation accuracy: {results['info']['final_val_acc']:.1%}\")\n",
        "else:\n",
        "    print(f\"Training failed: {results.get('error')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## Step 5: Save Trained Model to Google Drive\n",
        "\n",
        "Copy the trained model back to your Google Drive so you can download it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_to_drive"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Source paths\n",
        "model_path = \"/content/Project_DigitalWitness/models/lstm_classifier.pt\"\n",
        "info_path = \"/content/Project_DigitalWitness/models/lstm_classifier_info.json\"\n",
        "\n",
        "# Destination (Google Drive)\n",
        "drive_dest = \"/content/drive/MyDrive/DigitalWitness_Models/\"\n",
        "os.makedirs(drive_dest, exist_ok=True)\n",
        "\n",
        "# Copy files\n",
        "if os.path.exists(model_path):\n",
        "    shutil.copy(model_path, drive_dest)\n",
        "    print(f\"Copied: lstm_classifier.pt\")\n",
        "else:\n",
        "    print(\"ERROR: Model file not found!\")\n",
        "\n",
        "if os.path.exists(info_path):\n",
        "    shutil.copy(info_path, drive_dest)\n",
        "    print(f\"Copied: lstm_classifier_info.json\")\n",
        "\n",
        "print(f\"\\nFiles saved to: {drive_dest}\")\n",
        "print(\"\\nYou can now download from Google Drive:\")\n",
        "print(\"  drive.google.com → DigitalWitness_Models folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6"
      },
      "source": [
        "## Step 6: (Optional) Quick Test - Run Inference\n",
        "\n",
        "Test the trained model on a sample video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_model"
      },
      "outputs": [],
      "source": [
        "# Optional: Test the trained model\n",
        "from src.models.lstm_classifier import LSTMIntentClassifier\n",
        "from src.models.cnn_feature_extractor import CNNFeatureExtractor\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load trained model\n",
        "lstm = LSTMIntentClassifier(input_dim=512, num_classes=2)\n",
        "lstm.load_model(\"/content/Project_DigitalWitness/models/lstm_classifier.pt\")\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Classes: {lstm.classes}\")\n",
        "print(\"\\nModel is ready for inference.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
