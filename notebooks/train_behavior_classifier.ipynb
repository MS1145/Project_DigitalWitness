{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Witness - Behavior Classifier Training\n",
    "\n",
    "This notebook trains and evaluates the ML model for classifying shopping behaviors:\n",
    "- **normal**: Regular shopping activity\n",
    "- **pickup**: Product pickup from shelf\n",
    "- **concealment**: Hiding products (suspicious)\n",
    "- **bypass**: Checkout bypass (suspicious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "N_SAMPLES_PER_CLASS = 300\n",
    "N_FEATURES = 21\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "\n",
    "BEHAVIOR_CLASSES = [\"normal\", \"pickup\", \"concealment\", \"bypass\"]\n",
    "MODELS_DIR = project_root / \"models\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Synthetic Data Generation\n",
    "\n",
    "Generate realistic synthetic training data based on characteristic behavioral patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Feature names for interpretability\nFEATURE_NAMES = [\n    \"left_hand_velocity_mean\", \"left_hand_velocity_max\",\n    \"right_hand_velocity_mean\", \"right_hand_velocity_max\",\n    \"left_hand_body_dist_mean\", \"left_hand_body_dist_min\",\n    \"right_hand_body_dist_mean\", \"right_hand_body_dist_min\",\n    \"left_elbow_angle_mean\", \"left_elbow_angle_std\",\n    \"right_elbow_angle_mean\", \"right_elbow_angle_std\",\n    \"body_displacement_x\", \"body_displacement_y\",\n    \"body_velocity_mean\", \"body_velocity_max\",\n    \"left_hand_height_mean\", \"left_hand_height_min\",\n    \"right_hand_height_mean\", \"right_hand_height_min\",\n    \"pose_detection_rate\"\n]\n\ndef generate_class_features(behavior: str, n_samples: int, n_features: int) -> np.ndarray:\n    \"\"\"Generate synthetic features for a specific behavior class with optimized vectorization.\"\"\"\n    rng = np.random.default_rng(RANDOM_STATE + hash(behavior) % 1000)\n    features = rng.standard_normal((n_samples, n_features)) * 0.1\n    \n    # Feature indices:\n    # 0-3: Hand velocities, 4-7: Hand-body distances, 8-11: Elbow angles\n    # 12-15: Body trajectory, 16-19: Hand heights, 20: Pose detection rate\n    \n    # Define feature ranges for each behavior (separate from detection rate)\n    feature_ranges = {\n        \"normal\": [\n            ((0, 4), (0.02, 0.08)),   # Moderate velocity\n            ((4, 8), (0.2, 0.4)),     # Hands away from body\n            ((8, 12), (120, 160)),    # Relaxed arms\n            ((12, 16), (-0.1, 0.1)),  # Minimal displacement\n            ((16, 20), (-0.1, 0.1)), # Hands at mid level\n        ],\n        \"pickup\": [\n            ((0, 4), (0.08, 0.2)),    # High velocity\n            ((4, 8), (0.3, 0.6)),     # Reaching out\n            ((8, 12), (90, 140)),     # Extended arms\n            ((12, 16), (-0.05, 0.05)),# Stationary\n            ((16, 20), (0.0, 0.3)),   # Hands above shoulders\n        ],\n        \"concealment\": [\n            ((0, 4), (0.05, 0.15)),   # Moderate velocity\n            ((4, 8), (0.05, 0.15)),   # Very close to body\n            ((8, 12), (30, 80)),      # Bent arms\n            ((12, 16), (-0.05, 0.05)),# Stationary\n            ((16, 20), (-0.3, -0.1)), # Hands low (pocket level)\n        ],\n        \"bypass\": [\n            ((0, 4), (0.03, 0.1)),    # Moderate velocity\n            ((4, 8), (0.15, 0.3)),    # Normal distance\n            ((8, 12), (100, 150)),    # Normal arms\n            ((12, 16), (0.15, 0.4)),  # Large displacement\n            ((16, 20), (-0.15, 0.05)),# Hands normal\n        ]\n    }\n    \n    detection_rates = {\n        \"normal\": (0.8, 1.0),\n        \"pickup\": (0.85, 1.0),\n        \"concealment\": (0.7, 0.95),\n        \"bypass\": (0.75, 1.0)\n    }\n    \n    # Apply feature ranges\n    for (start, end), (low, high) in feature_ranges[behavior]:\n        features[:, start:end] += rng.uniform(low, high, (n_samples, end - start))\n    \n    # Set detection rate\n    features[:, 20] = rng.uniform(*detection_rates[behavior], n_samples)\n    \n    return features\n\ndef generate_training_data(n_samples_per_class: int = N_SAMPLES_PER_CLASS) -> tuple:\n    \"\"\"Generate complete synthetic training dataset.\"\"\"\n    np.random.seed(RANDOM_STATE)\n    \n    features_list = []\n    labels_list = []\n    \n    for class_idx, behavior in enumerate(BEHAVIOR_CLASSES):\n        class_features = generate_class_features(behavior, n_samples_per_class, N_FEATURES)\n        features_list.append(class_features)\n        labels_list.extend([class_idx] * n_samples_per_class)\n    \n    features = np.vstack(features_list)\n    labels = np.array(labels_list)\n    \n    # Shuffle\n    shuffle_idx = np.random.permutation(len(labels))\n    return features[shuffle_idx], labels[shuffle_idx]\n\n# Generate data\nX, y = generate_training_data()\nprint(f\"Dataset shape: {X.shape}\")\nprint(f\"Class distribution: {np.bincount(y)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for analysis\n",
    "df = pd.DataFrame(X, columns=FEATURE_NAMES)\n",
    "df['behavior'] = [BEHAVIOR_CLASSES[i] for i in y]\n",
    "\n",
    "# Display statistics\n",
    "print(\"Feature Statistics by Behavior Class:\")\n",
    "print(\"=\" * 60)\n",
    "df.groupby('behavior')[FEATURE_NAMES[:4]].mean().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key distinguishing features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "key_features = [\n",
    "    ('left_hand_body_dist_mean', 'Hand-Body Distance'),\n",
    "    ('left_elbow_angle_mean', 'Elbow Angle'),\n",
    "    ('body_displacement_x', 'Body Displacement'),\n",
    "    ('left_hand_height_mean', 'Hand Height')\n",
    "]\n",
    "\n",
    "for ax, (feat, title) in zip(axes.flat, key_features):\n",
    "    for behavior in BEHAVIOR_CLASSES:\n",
    "        data = df[df['behavior'] == behavior][feat]\n",
    "        ax.hist(data, bins=30, alpha=0.5, label=behavior, density=True)\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{title} Distribution by Behavior')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'feature_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr = df[FEATURE_NAMES].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=False, cmap='coolwarm', center=0,\n",
    "            xticklabels=range(len(FEATURE_NAMES)), yticklabels=range(len(FEATURE_NAMES)))\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'feature_correlation.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison\n",
    "\n",
    "Compare multiple classifiers to find the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=10, random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, max_depth=5, random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'SVM (RBF)': SVC(\n",
    "        kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE, class_weight='balanced', probability=True\n",
    "    )\n",
    "}\n",
    "\n",
    "# Cross-validation comparison\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "\n",
    "print(\"Cross-Validation Results (5-Fold):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    results[name] = scores\n",
    "    print(f\"{name:20s}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "positions = range(1, len(results) + 1)\n",
    "bp = plt.boxplot([results[name] for name in results.keys()], positions=positions, widths=0.6)\n",
    "plt.xticks(positions, results.keys())\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison (5-Fold Cross-Validation)')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'model_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf_base, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score (weighted): {test_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=BEHAVIOR_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=BEHAVIOR_CLASSES, yticklabels=BEHAVIOR_CLASSES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'confusion_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=BEHAVIOR_CLASSES, yticklabels=BEHAVIOR_CLASSES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'confusion_matrix_normalized.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': FEATURE_NAMES,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'feature_importance.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.tail(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save model with scaler and metadata\nmodel_path = MODELS_DIR / 'behavior_classifier.pkl'\n\nmodel_data = {\n    'model': best_model,\n    'scaler': scaler,\n    'feature_mean': scaler.mean_,\n    'feature_std': scaler.scale_,\n    'classes': BEHAVIOR_CLASSES,\n    'feature_names': FEATURE_NAMES,\n    'best_params': grid_search.best_params_,\n    'test_accuracy': test_accuracy,\n    'test_f1': test_f1\n}\n\njoblib.dump(model_data, model_path)\nprint(f\"Model saved to: {model_path}\")\nprint(f\"Model size: {model_path.stat().st_size / 1024:.1f} KB\")\n\n# Also save human-readable JSON with model metadata (not the model itself)\nimport json\n\nmodel_info_path = MODELS_DIR / 'behavior_classifier_info.json'\nmodel_info = {\n    'model_type': 'RandomForestClassifier',\n    'classes': BEHAVIOR_CLASSES,\n    'feature_names': FEATURE_NAMES,\n    'best_params': grid_search.best_params_,\n    'test_accuracy': float(test_accuracy),\n    'test_f1': float(test_f1),\n    'cv_accuracy': float(grid_search.best_score_),\n    'n_estimators': best_model.n_estimators,\n    'n_features': best_model.n_features_in_,\n    'feature_importances': {name: float(imp) for name, imp in zip(FEATURE_NAMES, feature_importance)},\n    'scaler_mean': scaler.mean_.tolist(),\n    'scaler_std': scaler.scale_.tolist()\n}\n\nwith open(model_info_path, 'w') as f:\n    json.dump(model_info, f, indent=2)\n\nprint(f\"\\nHuman-readable model info saved to: {model_info_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8.1 Inspect .pkl File Contents\n\nThe `.pkl` file is a binary format, but we can inspect what's inside it:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Inspect what's inside the .pkl file\nprint(\"Contents of behavior_classifier.pkl:\")\nprint(\"=\" * 50)\n\nfor key, value in model_data.items():\n    if key == 'model':\n        print(f\"\\n{key}:\")\n        print(f\"  Type: {type(value).__name__}\")\n        print(f\"  Number of trees: {value.n_estimators}\")\n        print(f\"  Max depth: {value.max_depth}\")\n        print(f\"  Number of features: {value.n_features_in_}\")\n        print(f\"  Classes: {value.classes_}\")\n    elif key == 'scaler':\n        print(f\"\\n{key}:\")\n        print(f\"  Type: {type(value).__name__}\")\n        print(f\"  Features scaled: {len(value.mean_)}\")\n    elif key in ['feature_mean', 'feature_std']:\n        print(f\"\\n{key}: array of {len(value)} values\")\n        print(f\"  First 5: {value[:5].round(4)}\")\n    elif key == 'classes':\n        print(f\"\\n{key}: {value}\")\n    elif key == 'feature_names':\n        print(f\"\\n{key}: {len(value)} features\")\n    else:\n        print(f\"\\n{key}: {value}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize one decision tree from the forest\nfrom sklearn.tree import plot_tree\n\nfig, ax = plt.subplots(figsize=(20, 10))\nplot_tree(best_model.estimators_[0], \n          feature_names=FEATURE_NAMES,\n          class_names=BEHAVIOR_CLASSES,\n          filled=True,\n          rounded=True,\n          max_depth=3,  # Only show first 3 levels for readability\n          fontsize=8,\n          ax=ax)\nplt.title('Sample Decision Tree from Random Forest (depth limited to 3)')\nplt.tight_layout()\nplt.savefig(MODELS_DIR / 'sample_tree.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nThis is just ONE of the\", best_model.n_estimators, \"trees in the forest.\")\nprint(\"The .pkl file stores ALL these trees with their complete structure.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify saved model\n",
    "loaded_data = joblib.load(model_path)\n",
    "loaded_model = loaded_data['model']\n",
    "loaded_scaler = loaded_data['scaler']\n",
    "\n",
    "# Test prediction\n",
    "X_test_loaded = loaded_scaler.transform(X_test)\n",
    "y_pred_loaded = loaded_model.predict(X_test_loaded)\n",
    "\n",
    "print(f\"Loaded model accuracy: {accuracy_score(y_test, y_pred_loaded):.4f}\")\n",
    "print(f\"Predictions match: {np.all(y_pred == y_pred_loaded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference\n",
    "def predict_behavior(features: np.ndarray) -> dict:\n",
    "    \"\"\"Predict behavior from feature vector.\"\"\"\n",
    "    features_scaled = loaded_scaler.transform(features.reshape(1, -1))\n",
    "    pred = loaded_model.predict(features_scaled)[0]\n",
    "    proba = loaded_model.predict_proba(features_scaled)[0]\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': BEHAVIOR_CLASSES[pred],\n",
    "        'confidence': float(proba[pred]),\n",
    "        'probabilities': {cls: float(p) for cls, p in zip(BEHAVIOR_CLASSES, proba)}\n",
    "    }\n",
    "\n",
    "# Test with a sample\n",
    "sample_features = X_test[0]\n",
    "result = predict_behavior(sample_features)\n",
    "print(f\"Sample prediction:\")\n",
    "print(f\"  Predicted: {result['predicted_class']}\")\n",
    "print(f\"  Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"  Actual: {BEHAVIOR_CLASSES[y_test[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: {len(y)} samples, {N_FEATURES} features\")\n",
    "print(f\"Classes: {', '.join(BEHAVIOR_CLASSES)}\")\n",
    "print(f\"Train/Test split: {1-TEST_SIZE:.0%}/{TEST_SIZE:.0%}\")\n",
    "print(f\"\\nBest Model: Random Forest\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "print(f\"  Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"  Test F1 score: {test_f1:.4f}\")\n",
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}